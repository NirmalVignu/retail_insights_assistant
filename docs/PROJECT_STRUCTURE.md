# Retail Insights Assistant - Production Structure

## ğŸ“ Project Structure

```
retail_insights_assistant/
â”œâ”€â”€ app_new.py                      # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env                            # Environment configuration (not for submission)
â”œâ”€â”€ .env.example                    # API key template for submission
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ README.md                       # Main documentation
â”œâ”€â”€ Retail_Insights_Assistant_Screenshots.pdf  # Screenshots & demo documentation
â”‚
â”œâ”€â”€ src/                            # Source code (organized)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                     # Multi-agent system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ multi_agent.py          # 4 specialized agents
â”‚   â”‚   â””â”€â”€ summarization_engine.py # Business intelligence reports
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                      # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ langgraph_agent.py      # 7-node state machine
â”‚   â”‚   â””â”€â”€ enhanced_query_resolution.py # SQL query architect
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                      # Utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration constants
â”‚   â”‚   â”œâ”€â”€ llm_config.py           # LLM provider setup
â”‚   â”‚   â”œâ”€â”€ data_processor.py       # DuckDB data engine
â”‚   â”‚   â”œâ”€â”€ conversation_memory.py  # RAG-based memory
â”‚   â”‚   â”œâ”€â”€ response_formatter.py   # Response formatting
â”‚   â”‚   â”œâ”€â”€ input_loader.py         # File loading utilities
â”‚   â”‚   â”œâ”€â”€ pdf_report_generator.py # PDF export
â”‚   â”‚   â””â”€â”€ prompt_loader.py        # Prompt management
â”‚   â”‚
â”‚   â””â”€â”€ ui/                         # UI components
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ qa_tab.py              # Q&A tab component
â”‚
â”œâ”€â”€ prompts/                        # Externalized prompt templates
â”‚   â”œâ”€â”€ query_resolution_prompt.txt       # Query intent analysis
â”‚   â”œâ”€â”€ query_decomposition_prompt.txt    # Complex query breakdown
â”‚   â”œâ”€â”€ llm_analysis_prompt.txt           # LLM-based insights
â”‚   â”œâ”€â”€ validation_analyst_prompt.txt     # Result validation
â”‚   â”œâ”€â”€ data_analyst_prompt.txt           # Statistical analysis
â”‚   â”œâ”€â”€ summarization_prompt.txt          # Business reports
â”‚   â””â”€â”€ comparison_prompt.txt             # Table comparison
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # System architecture (15 slides)  
â”‚   â”œâ”€â”€ LANGGRAPH_VISUALIZATION.md # LangGraph workflow diagram
â”‚   â”œâ”€â”€ AGENT_COMPARISON.md        # Dual agent architecture guide
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md       # This file
â”‚   â””â”€â”€ SCALABILITY_DESIGN.md      # 100GB+ scaling guide
â”‚
â”œâ”€â”€ screenshots/                   # Application screenshots (14 images)
â”‚   â”œâ”€â”€ 01_landing_page.png.jpg
â”‚   â”œâ”€â”€ 02_summary_page.jpg
â”‚   â”œâ”€â”€ 03_QA_Chat_LG_*.jpg
â”‚   â”œâ”€â”€ 04_data_analyst_*.jpg
â”‚   â”œâ”€â”€ 05_data_explorer.jpg
â”‚   â””â”€â”€ langgraph_viz.jpg         # LangGraph workflow visualization
â”‚
â”œâ”€â”€ data/                          # Sample datasets
â”‚   â””â”€â”€ Sales Dataset/
â”‚       â”œâ”€â”€ Amazon Sale Report.csv
â”‚       â”œâ”€â”€ Sale Report.csv
â”‚       â”œâ”€â”€ International sale Report.csv
â”‚       â””â”€â”€ May-2022.csv
â”‚
â”œâ”€â”€ config/                        # Configuration (optional)
â”‚   â””â”€â”€ (reserved for future config files)
â”‚
â””â”€â”€ tests/                         # Unit tests (future)
    â””â”€â”€ (reserved for test files)
```

## ğŸš€ Quick Start

```bash
# Run the application
streamlit run app_new.py
```

## ğŸ“¦ Installation

```bash
# 1. Clone/Download project
cd retail_insights_assistant

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 4. Run application
streamlit run app_new.py
```

## ğŸ¯ Key Features

### 1. **Organized Code Structure** 
- Agents in `src/agents/`
- LangGraph workflow in `src/graph/`
- Utilities in `src/utils/`
- UI components in `src/ui/`

### 2. **Externalized Prompts**
- All LLM prompts in `prompts/` folder
- Easy to edit without touching code
- Version control friendly
- Supports A/B testing and experimentation

### 3. **Professional Imports**
```python
# Organized modular imports
from src.agents import MultiAgentOrchestrator
from src.graph import LangGraphAgent
from src.utils import load_prompt, format_prompt
```

### 4. **Dynamic Prompt Management**
```python
# Load prompt from file
from src.utils import load_prompt, format_prompt

# Simple loading
prompt = load_prompt("summarization_prompt")

# With variable substitution
prompt = format_prompt(
    "query_resolution_prompt",
    schema_info=schema_data,
    context_part=previous_conversation
)
```

## ğŸ“ Usage Examples

### Import from New Structure
```python
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Import agents
from src.agents import MultiAgentOrchestrator, DataAnalystAgent
from src.graph import LangGraphAgent
from src.utils import get_processor, get_llm, load_prompt

# Use in code
agent = LangGraphAgent(processor=get_processor())
result = agent.process_query("What is total revenue?")
```

### Edit Prompts
1. Open `prompts/query_resolution_prompt.txt`
2. Edit the text directly
3. Save file
4. Changes take effect immediately (cached prompts can be reloaded)

### Add New Prompt
1. Create `prompts/my_new_prompt.txt`
2. Write prompt content
3. Load in code: prompt_loader.load_prompt("my_new_prompt")

## ğŸ”§ Configuration

### Environment Variables (.env)
```bash
# LLM Provider (gemini or openai)
LLM_PROVIDER=gemini

# API Keys
GEMINI_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here

# Database
DATABASE_PATH=sales_data.duckdb
CSV_DATA_PATH=Assignment/Sales Dataset/

# Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2
```

### Config File (src/utils/config.py)
All configuration constants in one place:
- `PAGE_TITLE`
- `DATABASE_PATH`
- `CSV_DATA_PATH`
- `EMBEDDING_MODEL`

## ğŸ§ª Testing

```bash
# Test imports
python -c "from src.agents import MultiAgentOrchestrator; print('âœ“ Imports work!')"

# Test prompt loading
python -c "from src.utils import load_prompt; print(load_prompt('summarization_prompt')[:100])"

# Run application
streamlit run app_new.py
```

## ğŸ“š Documentation Files

- **Setup Guide**: `README.md` - Installation, configuration, usage instructions
- **Architecture**: `docs/ARCHITECTURE.md` - 15-slide technical architecture + LangGraph visualization
- **Agent Comparison**: `docs/AGENT_COMPARISON.md` - Dual agent system explained
- **LangGraph Workflow**: `docs/LANGGRAPH_VISUALIZATION.md` - 7-node state machine diagram
- **Scalability**: `docs/SCALABILITY_DESIGN.md` - 100GB+ production design
- **Screenshots**: `Retail_Insights_Assistant_Screenshots.pdf` - Complete demo with 14 images
- **Project Structure**: `docs/PROJECT_STRUCTURE.md` - This file



## ğŸ› Troubleshooting

### Import Errors
```python
# Make sure src/ is in path
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / "src"))
```

### Prompt Not Found
```python
# Check prompts/ directory exists
# Check filename matches (case-sensitive)
# Check .txt extension

from src.utils import get_prompt_loader
loader = get_prompt_loader()
print(loader.list_available_prompts())  # List all prompts
```

### Module Not Found
```bash
# Reinstall dependencies
pip install -r requirements.txt

# Verify Python version (3.9+)
python --version
```

### Application Won't Start
```bash
# Clear cache
Remove-Item -Recurse -Force -ErrorAction SilentlyContinue __pycache__, src\__pycache__, src\*\__pycache__

# Restart Streamlit
streamlit run app_new.py
```

## ğŸ“ Support

For issues:
1. Check main `README.md` troubleshooting section
2. Review error logs in terminal
3. Verify `.env` configuration is correct

